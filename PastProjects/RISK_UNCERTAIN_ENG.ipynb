{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"RISK_UNCERTAIN_ENG.ipynb","provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"WIfEX6IJxbmB","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1594889417031,"user_tz":-120,"elapsed":1908,"user":{"displayName":"Pietro Aluffi","photoUrl":"","userId":"17452554345431253162"}},"outputId":"f0249a54-63a0-4e89-c0a4-4568a4f2f964"},"source":["from google.colab import drive\n","drive.mount('/content/gdrive', force_remount=True)"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"BajGlXq1aw_G","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1594889420031,"user_tz":-120,"elapsed":1751,"user":{"displayName":"Pietro Aluffi","photoUrl":"","userId":"17452554345431253162"}}},"source":["import pandas as pd\n","import numpy as np\n","import nltk\n","import regex\n","import gensim\n","from gensim.utils import lemmatize\n","from gensim.utils import simple_preprocess\n","import spacy #python3 -m spacy download en\n","from spacy.lang.en.stop_words import STOP_WORDS as en\n","from wordcloud import WordCloud\n","from matplotlib import pyplot as plt"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"UreRJUY5ExBZ","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1594889422416,"user_tz":-120,"elapsed":820,"user":{"displayName":"Pietro Aluffi","photoUrl":"","userId":"17452554345431253162"}}},"source":[""],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"fiE6asjocUWq","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":436},"executionInfo":{"status":"ok","timestamp":1594889425358,"user_tz":-120,"elapsed":2505,"user":{"displayName":"Pietro Aluffi","photoUrl":"","userId":"17452554345431253162"}},"outputId":"169f097e-d76a-4905-c6e0-a88e954a5dee"},"source":["df = pd.read_csv('/content/gdrive/My Drive/Research/Datasets/ft2020all.csv')\n","# df[df['Date'] == 'yesterday']['Date']\n","df.loc[df['Date'] == 'yesterday', 'Date'] = '2020-07-14'\n","df.loc[df['Date'] == '5 hours ago', 'Date'] = '2020-07-14'\n","df.loc[df['Date'] == '2 hours ago', 'Date'] = '2020-07-14'\n","df.loc[df['Date'] == '4 hours ago', 'Date'] = '2020-07-14'\n","df['Date'] =pd.to_datetime(df.Date)\n","df =df.dropna().set_index('Date').sort_index()\n","texts = df.Article.values.tolist()\n","df = df.assign(weekoftheyear=pd.PeriodIndex(df.index, freq='D'))\n","ind = (df.weekoftheyear.unique())\n","len(df)\n","df"],"execution_count":3,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Unnamed: 0</th>\n","      <th>Title</th>\n","      <th>Article</th>\n","      <th>weekoftheyear</th>\n","    </tr>\n","    <tr>\n","      <th>Date</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>2020-01-01</th>\n","      <td>0</td>\n","      <td>Hello, Robot: machines designed for comfort — ...</td>\n","      <td>In the 1930s there were two kinds of robot sto...</td>\n","      <td>2020-01-01</td>\n","    </tr>\n","    <tr>\n","      <th>2020-01-01</th>\n","      <td>24</td>\n","      <td>ADHD app: game theory</td>\n","      <td>For parents with young children, video games c...</td>\n","      <td>2020-01-01</td>\n","    </tr>\n","    <tr>\n","      <th>2020-01-01</th>\n","      <td>25</td>\n","      <td>The EU needs to learn the language of power</td>\n","      <td>More than three years have passed since EU lea...</td>\n","      <td>2020-01-01</td>\n","    </tr>\n","    <tr>\n","      <th>2020-01-01</th>\n","      <td>26</td>\n","      <td>Harry Potter at 40: would he be a financial wi...</td>\n","      <td>Fans of Harry Potter, immortalised in fiction ...</td>\n","      <td>2020-01-01</td>\n","    </tr>\n","    <tr>\n","      <th>2020-01-01</th>\n","      <td>27</td>\n","      <td>South Korean export decline slows on China shi...</td>\n","      <td>South Korean exports marked the smallest decli...</td>\n","      <td>2020-01-01</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>2020-07-14</th>\n","      <td>21036</td>\n","      <td>India takes a risk by encouraging national int...</td>\n","      <td>Soon after India announced it was banning 59 p...</td>\n","      <td>2020-07-14</td>\n","    </tr>\n","    <tr>\n","      <th>2020-07-14</th>\n","      <td>21034</td>\n","      <td>UK’s largest accounting firms lambasted by wat...</td>\n","      <td>The UK’s biggest accounting firms have been cr...</td>\n","      <td>2020-07-14</td>\n","    </tr>\n","    <tr>\n","      <th>2020-07-14</th>\n","      <td>21033</td>\n","      <td>Petropavlovsk revival at risk after boardroom ...</td>\n","      <td>Petropavlovsk shareholders thought the company...</td>\n","      <td>2020-07-14</td>\n","    </tr>\n","    <tr>\n","      <th>2020-07-14</th>\n","      <td>21048</td>\n","      <td>Offshore investors dump China stocks after ‘in...</td>\n","      <td>Offshore investors cashed out of Chinese stock...</td>\n","      <td>2020-07-14</td>\n","    </tr>\n","    <tr>\n","      <th>2020-07-14</th>\n","      <td>21122</td>\n","      <td>Ashmore Group: bond bail</td>\n","      <td>As a proxy on emerging markets, fund manager A...</td>\n","      <td>2020-07-14</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>20229 rows × 4 columns</p>\n","</div>"],"text/plain":["            Unnamed: 0  ... weekoftheyear\n","Date                    ...              \n","2020-01-01           0  ...    2020-01-01\n","2020-01-01          24  ...    2020-01-01\n","2020-01-01          25  ...    2020-01-01\n","2020-01-01          26  ...    2020-01-01\n","2020-01-01          27  ...    2020-01-01\n","...                ...  ...           ...\n","2020-07-14       21036  ...    2020-07-14\n","2020-07-14       21034  ...    2020-07-14\n","2020-07-14       21033  ...    2020-07-14\n","2020-07-14       21048  ...    2020-07-14\n","2020-07-14       21122  ...    2020-07-14\n","\n","[20229 rows x 4 columns]"]},"metadata":{"tags":[]},"execution_count":3}]},{"cell_type":"code","metadata":{"id":"7Rm_h09XcvcM","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1594889435081,"user_tz":-120,"elapsed":9214,"user":{"displayName":"Pietro Aluffi","photoUrl":"","userId":"17452554345431253162"}}},"source":["#regular expression: formatting text\n","def formatting(texts):\n","    texts = [regex.sub('\\s+', ' ', text) for text in texts] #remove new lines\n","    texts = [regex.sub(\"\\\"\", \"\", text) for text in texts] #remove quotations\n","    texts = [regex.sub(\"\\'\", \"\", text) for text in texts] #remove quotations\n","    return texts\n","formatted_text = formatting(texts)"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"oKB4SNcxcxAB","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":52},"executionInfo":{"status":"ok","timestamp":1594890284893,"user_tz":-120,"elapsed":857554,"user":{"displayName":"Pietro Aluffi","photoUrl":"","userId":"17452554345431253162"}},"outputId":"c7c4bc40-8d03-4cc9-d948-4a225b4307c8"},"source":["stop_words = list(en)\n","stop_words.extend(['per','bn','mr','cent','say','new','use','per','not', 'would', 'say', 'could', '_', 'be', 'know', 'good', 'go', 'get', 'do', 'done', 'try', 'many', 'some', 'nice', 'thank', 'think', 'see', 'rather', 'easy', 'easily', 'lot', 'lack', 'make', 'want', 'seem', 'run', 'need', 'even', 'right', 'line', 'even', 'also', 'may', 'take', 'come','q','w','e','r','t','y','u','i','o','p','a','s','d','f','g','h','j','k','l','z','x','c','v','b','n','m','ty'])\n","lemma = spacy.load('en', disable=['parser', 'ner'])\n","\n","def token(sentences):\n","    for sentence in sentences:\n","        yield(gensim.utils.simple_preprocess(str(sentence),deacc=True)) \n","\n","def bigram_trigram(texts):\n","    bigram = gensim.models.Phrases(texts)\n","    trigram = gensim.models.Phrases(bigram[texts])\n","    bigram_ = gensim.models.phrases.Phraser(bigram)\n","    trigram_ = gensim.models.phrases.Phraser(trigram)\n","    texts = [[word for word in doc if word not in stop_words] for doc in texts] \n","    bi = [bigram_[text] for text in texts]\n","    tri = [trigram_[bigram_[b]] for b in bi]\n","    return tri\n","def processing(texts, stop_words=stop_words):\n","    texts = [[word for word in doc if word not in stop_words] for doc in texts]\n","    output = []\n","    for text in texts:\n","        doc = lemma(\" \".join(text)) \n","        output.append([token.lemma_ for token in doc])\n","    # remove stopwords once more after lemmatization\n","    output = [[word for word in doc if word not in stop_words] for doc in output]\n","    return output\n","\n","tokens = list(token(formatted_text))\n","bi_tri = bigram_trigram(tokens)\n","final_data = processing(bi_tri)\n","df['ProcessedArticles'] = final_data"],"execution_count":5,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n","  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"Tr_j47TDsR6d","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1594890284895,"user_tz":-120,"elapsed":855472,"user":{"displayName":"Pietro Aluffi","photoUrl":"","userId":"17452554345431253162"}}},"source":["def search_risk(text,n):\n","    word = r'\\W*([\\w]+)'\n","    risk = regex.findall(r'{}\\W*{}{}'.format(word*n,'risk',word*n), text)\n","    uncertainty = regex.findall(r'{}\\W*{}{}'.format(word*n,'uncertainty',word*n), text)\n","    uncertain = regex.findall(r'{}\\W*{}{}'.format(word*n,'uncertain',word*n), text)\n","    fear = regex.findall(r'{}\\W*{}{}'.format(word*n,'fear',word*n), text)\n","    return risk+uncertainty+uncertain+fear"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"9j8_D6RIsUB4","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1594899062746,"user_tz":-120,"elapsed":1004759,"user":{"displayName":"Pietro Aluffi","photoUrl":"","userId":"17452554345431253162"}}},"source":["risk = [(search_risk(' '.join(data),10)) for data in final_data ]"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"tQYDmb8RsdSv","colab_type":"code","colab":{}},"source":["# df['Risk'] = risk\n","# len(risk)\n","# df.to_csv('/content/gdrive/My Drive/Research/Datasets/final_risk_10ENG.csv')\n","# df = pd.read_csv('/content/gdrive/My Drive/Research/Datasets/final_risk_10ENG.csv').set_index('Date')\n","# risk = df.Risk.tolist()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1YHwVEiKvSoD","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":277},"executionInfo":{"status":"error","timestamp":1594853677704,"user_tz":-120,"elapsed":646,"user":{"displayName":"Pietro Aluffi","photoUrl":"","userId":"17452554345431253162"}},"outputId":"a0b85fe0-f879-4568-8a8d-4d2c6d5c26dd"},"source":["stop_words.extend(['latest_storie','january','february','march','april','may','june','july','august','september','october','november','december','y_asset','likely','window_share','calere'])\n","df = df.assign(weekoftheyear=pd.PeriodIndex(df.index, freq='W'))\n","def frequency(data,top_N,term):\n","  freq = []\n","  for i in df['weekoftheyear'].unique():\n","    week_data = df[(df['weekoftheyear'] == i)][term]\n","    flat_list = [item for sublist in week_data for item in sublist]\n","    flat_list1 = [item for sublist in flat_list for item in sublist]\n","    output = [word for word in flat_list1 if word not in stop_words]\n","    word_dist = nltk.FreqDist(output)\n","    temp = pd.DataFrame(word_dist.most_common(),\n","                      columns=['Word', 'Frequency'])\n","    temp['Percentage'] = temp.Frequency / len(temp.Word) * 100\n","    freq.append(temp.head(20))\n","  return freq"],"execution_count":null,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-226c5184fb69>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mstop_words\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'latest_storie'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'january'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'february'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'march'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'april'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'may'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'june'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'july'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'august'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'september'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'october'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'november'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'december'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'y_asset'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'likely'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'window_share'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'calere'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweekoftheyear\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPeriodIndex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfreq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'W'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mfrequency\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtop_N\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mterm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0mfreq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'weekoftheyear'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'stop_words' is not defined"]}]},{"cell_type":"code","metadata":{"id":"2pO4j8TXHeOy","colab_type":"code","colab":{}},"source":["risk = frequency(df,20,'Risk')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CWlFrGKTH7sH","colab_type":"code","colab":{}},"source":["#  for i in range(len(risk)): \n","#   try:\n","#     word_dict = dict(zip(risk[i].Word, risk[i].Frequency))\n","\n","#     wordcloud = WordCloud(background_color=\"white\", width=900,height=500, max_words=1628,relative_scaling=1,normalize_plurals=False).generate_from_frequencies(word_dict)\n","#     plt.imshow(wordcloud)\n","#     print(('WEEK===' + str(i+1)))\n","#     plt.axis(\"off\")\n","#     plt.show()\n","#   except:\n","#     print('no data')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"D78kYa6N4T_d","colab_type":"code","colab":{}},"source":["df_risk = []\n","# df = df.assign(weekoftheyear=pd.PeriodIndex(df.index, freq='M'))\n","for i in range(len(risk)):\n","  a = (risk[i].Word.head(5).to_list())\n","  df_risk.append(a)\n","df_risk = pd.DataFrame(df_risk,columns=['Word1','Word2','Word3','Word4','Word5']).set_index(df.groupby('weekoftheyear').sum().index)\n","print(df_risk.to_latex())"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"huS99kFh4Wl7","colab_type":"code","colab":{}},"source":["df.groupby('weekoftheyear').sum()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YWiEy2h4Rndg","colab_type":"code","colab":{}},"source":["# [week.weekofyear for week in df.index]\n","i=2\n","for week in df.index:\n","  if week.weekofyear == i:\n","    print(week)\n","    i=i+1"],"execution_count":null,"outputs":[]}]}